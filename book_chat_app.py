# -*- coding: utf-8 -*-
"""
KU ì „ê³µ ë§ì¶¤ ë„ì„œì¶”ì²œ (RAG + BM25 + HyDE + Embedding Re-rank)
í•„ìš” íŒ¨í‚¤ì§€: streamlit, pandas, numpy, sqlalchemy, rank_bm25, openai, psycopg2-binary(ì„ íƒ)
"""

import os, re, json, hashlib
import os, re, sqlite3, pandas as pd, numpy as np
from typing import List, Dict, Tuple
from typing import Dict, Any
import numpy as np
import pandas as pd
import streamlit as st
from rank_bm25 import BM25Okapi
from collections import defaultdict
import html
from openai import OpenAI
from google.cloud import bigquery
from google.oauth2 import service_account


# ========= ìŠ¤íƒ€ì¼ (Korea University í†¤) =========
KU_CRIMSON = "#A6192E"
KU_BEIGE   = "#F7F3EE"
KU_GRAY    = "#4B4B4B"

with open("assets/korea_university.png", "rb") as f:
    st.set_page_config(page_title="ë„ì„œ ì¶”ì²œ ì±—ë´‡", page_icon=f.read(), layout="wide")


st.markdown(f"""
<style>
.stApp {{ background: #fff; }}
h1,h2,h3,h4 {{ color: {KU_CRIMSON} !important; }}
[data-testid="stSidebar"] > div:first-child {{
  background: {KU_BEIGE}; border-right: 1px solid rgba(0,0,0,0.06);
}}
.stButton>button, .stForm button[kind="primary"] {{
  background: {KU_CRIMSON} !important; color: #fff !important; border:none !important;
  border-radius: 10px !important; padding: 0.5rem 0.9rem !important;
}}
.rec-card {{ background:#fff; border:1px solid rgba(0,0,0,0.06); border-radius:16px;
             padding:14px 16px; box-shadow:0 8px 24px rgba(0,0,0,0.06); }}
.card-meta {{ color:{KU_GRAY}; font-size:0.9rem; }}
.card-reason-label {{ color:{KU_CRIMSON}; font-weight:700; }}
.chip {{
  display:inline-block; background:{KU_BEIGE}; border:1px solid rgba(0,0,0,0.06);
  border-radius:999px; padding:2px 10px; margin:2px 6px 2px 0; font-size:0.85rem; color:{KU_GRAY};
}}
hr.soft {{ border:none; border-top:1px solid rgba(0,0,0,.06); margin:8px 0 4px; }}
</style>
""", unsafe_allow_html=True)


#Secrets ì½ê¸°
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "").strip()
PROJECT_ID = st.secrets.get("PROJECT_ID", "").strip()
GCP_SA_INFO = st.secrets.get("gcp_service_account", None)

assert OPENAI_API_KEY.strip(), "í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”."
if not PROJECT_ID:
    raise RuntimeError("PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš” (.env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ í™•ì¸).")

client = OpenAI(api_key=OPENAI_API_KEY)

EMBED_MODEL = "text-embedding-3-small"
CHAT_MODEL  = "gpt-5-mini"


def get_bq_client(project_id: str, sa_info: dict) -> bigquery.Client:
    if not sa_info:
        st.error("gcp_service_accountê°€ Secretsì— ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    creds = service_account.Credentials.from_service_account_info(sa_info)
    return bigquery.Client(project=project_id or sa_info.get("project_id"), credentials=creds)

bq_client = get_bq_client(PROJECT_ID, GCP_SA_INFO)



TABLE = "korea_univ.dm_book_detail"
COL_TITLE  = "book"
COL_AUTHOR = "author"
COL_PUB    = "publisher"
COL_TEXT   = "openai"  

@st.cache_data(show_spinner=False)
def fn_query(sql: str) -> pd.DataFrame:
    return bq_client.query(sql).result().to_dataframe()


@st.cache_data(show_spinner=False)
def load_major_map() -> tuple[dict[str, list[str]], list[str]]:
    # DBì—ì„œ ì „ê³µ ëª©ë¡ ì½ì–´ì„œ {ë‹¨ê³¼ëŒ€:[í•™ê³¼...]} ë§µ êµ¬ì„±
    df_major = fn_query("""
        SELECT college, department
        FROM korea_univ.dm_major
    """)
    by_college: dict[str, list[str]] = defaultdict(list)
    for _, row in df_major.iterrows():
        by_college[row["college"]].append(row["department"])
    # ì •ë ¬/ì¤‘ë³µì œê±°
    for k in by_college.keys():
        by_college[k] = sorted(set(by_college[k]))
    college_list = sorted(by_college.keys())
    return by_college, college_list


df_books = fn_query('''SELECT * FROM korea_univ.dm_book_detail where author != '' ''')   
by_college, college_list = load_major_map()

# ========= ìœ í‹¸: í…ìŠ¤íŠ¸/íŒŒì‹± =========
def simple_tokenize(s: str) -> List[str]:
    s = (s or "").lower()
    s = re.sub(r"[^0-9a-zê°€-í£\s]", " ", s)
    return [w for w in s.split() if w.strip()]

def extract_section(text: str, n: int, title_kw: str) -> str:
    if not text:
        return ""
    
    text = text.replace("\\n", "\n")
    pat = rf"{n}\.\s*{title_kw}.*?\n([\s\S]+?)(?:\n\s*\d+\.\s|$)"
    m = re.search(pat, text)
    return (m.group(1).strip() if m else "").strip()

def extract_genre_from_gpt(text: str) -> str:
    # "4. ì¥ë¥´ ë° í•µì‹¬ í‚¤ì›Œë“œ" ì„¹ì…˜ ì²« ì¤„ì„ ì¥ë¥´ë¡œ ê°„ì£¼ (ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ì „ì²´ë¥¼ í•œ ì¤„ ìš”ì•½)
    block = extract_section(text, 4, "ì¥ë¥´")
    print('###################################3',block)
    if not block:
        return ""
    first_line = block.splitlines()[0].strip()
    # ì½¤ë§ˆ/ìŠ¬ë˜ì‹œ ê¸°ì¤€ ì •ë¦¬
    first_line = re.sub(r"\s*[,/]\s*", ", ", first_line)
    return first_line

def extract_summary_from_gpt(text: str) -> str:
    block = extract_section(text, 5, "ë‚´ìš© ìš”ì•½")
    return block if block else text


def detect_intent(q: str) -> str:
    if not q: 
        return "unknown"
    qs = q.strip().lower()
    # ì´ë¦„ ì§ˆë¬¸
    if any(k in qs for k in ["ì´ë¦„", "who are you", "what is your name", "ë„ˆ ì´ë¦„", 'ì•ˆë…•']):
        return "ask_name"
    # ê³µì—° ì¶”ì²œ/ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ
    rec_kw = ["ì¶”ì²œ", "ì°¾ì•„ì¤˜", "ì±…", "ë„ì„œ", "ì „ê³µ", "ì½", "ì•Œë ¤ì¤˜", "ê´€ì‹¬", "ì–´ë–¤"]
    if any(k in q for k in rec_kw):
        return "recommend"
    return "other"

# ========= BM25 ì¸ë±ìŠ¤ =========
@st.cache_resource(show_spinner=False)
def build_bm25_index(df: pd.DataFrame):
    docs = []
    for _, r in df.iterrows():
        summary = extract_summary_from_gpt(r[COL_TEXT])
        docs.append(simple_tokenize(f"{r[COL_TITLE]} {summary}"))
    return BM25Okapi(docs)

bm25 = build_bm25_index(df_books)

# ========= ì„ë² ë”© & Re-rank =========
@st.cache_data(show_spinner=False)
def embed_text(texts: List[str]) -> np.ndarray:
    if not client:
        # OPENAI_API_KEY ì—†ìœ¼ë©´ ëª¨ë‘ 0ìœ¼ë¡œ ë¦¬í„´(â†’ BM25ë§Œ ì‚¬ìš©)
        return np.zeros((len(texts), 1536), dtype=np.float32)
    resp = client.embeddings.create(model=EMBED_MODEL, input=texts)
    vecs = np.array([d.embedding for d in resp.data], dtype=np.float32)
    return vecs

def cosine_sim(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    a = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-8)
    b = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-8)
    return a @ b.T

def hyde_expand(query: str) -> str:
    if not client:
        return query
    sys = "ë„ˆëŠ” í•œêµ­ì–´ ë„ì„œ ì¶”ì²œ ë¹„ì„œë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì˜ ë°˜ì˜í•œ í•œ ë‹¨ë½ì˜ ê°€ìƒ ë‹µë³€ì„ ë§Œë“¤ì–´ ê²€ìƒ‰ ì„±ëŠ¥ì„ ë†’ì—¬ë¼."
    msg = [{"role":"system","content":sys},{"role":"user","content":query}]
    out = client.chat.completions.create(model=CHAT_MODEL, messages=msg)
    return (out.choices[0].message.content or "").strip()

def build_query_with_major(user_query: str) -> str:
    majors = st.session_state.get("selected_departments", []) or []
    if majors:
        return f"{user_query}\n\n[ì „ê³µí‚¤ì›Œë“œ] " + " / ".join(majors)
    return user_query

def rerank(query: str, df_cand: pd.DataFrame, top_k: int = 8, use_hyde: bool = True) -> List[Dict]:
    # HyDE ì¿¼ë¦¬ í™•ì¥
    q = hyde_expand(query) if (use_hyde and client) else query
    # í›„ë³´ í…ìŠ¤íŠ¸ êµ¬ì„±(ì œëª© + ìš”ì•½)
    texts = []
    rows = []
    for _, r in df_cand.iterrows():
        summary = extract_summary_from_gpt(r[COL_TEXT])
        texts.append(f"{r[COL_TITLE]}\n{summary}")
        rows.append(r)
    # ì„ë² ë”©
    q_vec = embed_text([q])           # (1,d)
    d_vecs = embed_text(texts)        # (n,d)
    sims = cosine_sim(q_vec, d_vecs)[0]  # (n,)
    order = np.argsort(-sims)[:top_k]
    out = []
    for idx in order:
        r = rows[idx]
        out.append({
            "title": r[COL_TITLE],
            "author": r[COL_AUTHOR],
            "publisher": r[COL_PUB],
            "text": r[COL_TEXT],
            "score": float(sims[idx]),
        })
    return out

# ========= ì¶”ì²œ ì´ìœ  ìƒì„± =========
def make_reasons(query: str, items: List[Dict]) -> List[str]:
    if not items:
        return []
    # ì¥ë¥´(í‚¤ì›Œë“œ) íŒŒì‹±ì„ ë¨¼ì € ìˆ˜í–‰
    for it in items:
        it["genre"] = extract_genre_from_gpt(it.get("text",""))

    # OPENAI_API_KEY ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ í•œ ì¤„ ìš”ì•½
    if not client:
        reasons = []
        for it in items:
            g = it.get("genre","")
            reasons.append(f"ìš”ì²­ê³¼ '{g}'(ìœ¼)ë¡œ ë¬˜ì‚¬ëœ ì£¼ì œê°€ ë§ë‹¿ì•„ ìˆìŠµë‹ˆë‹¤.")
        return reasons

    sys = "ë„ˆëŠ” í•œêµ­ì–´ ë„ì„œ ì¶”ì²œ ë¹„ì„œë‹¤. ê° ì±…ì´ ì‚¬ìš©ìì˜ ìš”ì²­Â·ì „ê³µ ë§¥ë½ì— ì™œ ë§ëŠ”ì§€ 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì¨ë¼."
    # ëª¨ë¸ ì…ë ¥ ì¶•ì•½
    book_blocks = []
    for i, it in enumerate(items, 1):
        desc = extract_summary_from_gpt(it.get("text",""))[:450]
        book_blocks.append({
            "idx": i,
            "title": it.get("title",""),
            "author": it.get("author",""),
            "publisher": it.get("publisher",""),
            "genre": it.get("genre",""),
            "detail": desc
        })
    usr = {
        "user_query": query,
        "format": "JSON list of objects with keys: idx, reason (Korean, 1~2 sentences).",
        "books": book_blocks
    }
    out = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role":"system","content":sys},
                  {"role":"user","content":json.dumps(usr, ensure_ascii=False)}],
    )
    txt = out.choices[0].message.content.strip()
    reasons = [""] * len(items)
    try:
        data = json.loads(txt)
        for obj in data:
            i = int(obj.get("idx", 0)) - 1
            if 0 <= i < len(items):
                reasons[i] = str(obj.get("reason","")).strip()
    except Exception:
        for i, it in enumerate(items):
            g = it.get("genre","")
            reasons[i] = f"ìš”ì²­ê³¼ '{g}' ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    return reasons

def short_acknowledge(user_q: str) -> str:
    """
    GPT-5-minië¥¼ ì‚¬ìš©í•´ ì§§ì€(1ë¬¸ì¥) ì‘ë‹µ ìƒì„±
    """
    sys = "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ê³µê°í•˜ë©° 1ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ë‹µí•˜ëŠ” ë¹„ì„œì•¼. ë„ˆê°€ ì±… ì¶”ì²œí•  í•„ìš”ëŠ” ì—†ì–´. ê³µê°ë§Œí•´. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì¡´ëŒ“ë§ë¡œ ì‘ë‹µí•´."
    msg = [
        {"role":"system","content":sys},
        {"role":"user","content":f"ì‚¬ìš©ìê°€ '{user_q}' ë¼ê³  ì§ˆë¬¸í–ˆì–´. 1ë¬¸ì¥ìœ¼ë¡œ ê³µê°í•˜ëŠ” ë¬¸ì¥ì„ ì§§ê²Œ ì‘ë‹µí•´ì¤˜."}
    ]
    try:
        out = client.chat.completions.create(model="gpt-5-mini", messages=msg)
        return out.choices[0].message.content.strip()
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        return "ë„¤, ì±… ì¶”ì²œì„ ì¤€ë¹„í•´ë“œë¦´ê²Œìš”!"

# ========= ì¹´ë“œ ë Œë” =========
def html_escape(text: str) -> str:
    return html.escape(text or "")


def render_book_card(item: Dict[str, Any], rank: int, reason: str = ""):
    """
    item: {
      title, author, publisher, genre, reason, score(optional)
    }
    """
    title_html  = html_escape(str(item.get("title", "")))
    author_html = html_escape(str(item.get("author", "")))
    pub_html    = html_escape(str(item.get("publisher", "")))
    genre_html  = html_escape(str(item.get("genre", "")))
    reason_html = html_escape(str(item.get("reason", ""))) or "ì´ ì±…ì´ ì í•©í•©ë‹ˆë‹¤!"

    score_val   = float(item.get("score", 0.0) or 0.0)
    score_help_html = (
        "<div style=\"font-size:12px;color:#64748b;display:flex;align-items:center;gap:6px;\">"
        f"<span>semantic score: {score_val:.4f}</span>"
        "<span class=\"tooltip\" "
        "data-tooltip=\"ì‚¬ìš©ì ì§ˆì˜ì™€ ì±… ì„¤ëª…ì˜ ì˜ë¯¸ ìœ ì‚¬ë„ë¥¼ 0~1ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n"
        "1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë” ì˜ ë§ì•„ìš”.\">â“˜ help</span></div>"
    )


    st.markdown(
        f"""
<div style="border:1px solid #e5e7eb;border-radius:14px;padding:14px 16px;margin:10px 0;background:#ffffff;">
  <div style="display:flex;justify-content:space-between;align-items:center;">
    <div style="font-size:18px;font-weight:700;">#{rank} {title_html}</div>
    {score_help_html}
  </div>

  <div style="margin-top:6px;color:#111827;display:flex;flex-wrap:wrap;gap:10px;">
    <span>âœï¸ <b> ì €ì</b> -{author_html}</span>
    <span>ğŸ¢ <b> ì¶œíŒì‚¬</b> -{pub_html}</span>
    <span>ğŸ“š <b> ì¥ë¥´</b> -{genre_html}</span>
  </div>

  <div style="margin-top:10px;line-height:1.5;">
    ğŸ§  <b>ì¶”ì²œì´ìœ </b> â€” {reason_html}
  </div>
</div>
""",
        unsafe_allow_html=True
    )

# ========= ì‚¬ì´ë“œë°”: ì „ê³µ ì„ íƒ (êµì°¨ ëˆ„ì  + ì¼ê´„ ì‚­ì œ + ë¹ ë¥¸ ë Œë”) =========
with st.sidebar:
    st.header("í•™ê³¼ ì„ íƒ")

    # ìƒíƒœ ì´ˆê¸°í™”
    if "selected_map" not in st.session_state:
        st.session_state["selected_map"] = {c: [] for c in college_list}
    else:
        for c in college_list:
            st.session_state["selected_map"].setdefault(c, [])

 
    selected_college = st.selectbox("ë‹¨ê³¼ëŒ€í•™", college_list, key="college_select")
    current_departments = by_college.get(selected_college, [])

    with st.form("dept_pick_form", clear_on_submit=False):
        selected_this_college = st.multiselect(
            "í•™ê³¼(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
            options=current_departments,
            default=st.session_state["selected_map"].get(selected_college, []),
            placeholder="í•™ê³¼ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            key=f"dept_multi_{selected_college}",
        )
        apply_pick = st.form_submit_button("ì„ íƒ ì ìš©")

    if apply_pick:
        st.session_state["selected_map"][selected_college] = selected_this_college
        st.rerun()

    # ì „ì²´ ì§‘ê³„
    all_pairs = [(c, d) for c in college_list for d in st.session_state["selected_map"][c]]
    st.session_state["selected_pairs"] = all_pairs
    st.session_state["selected_departments"] = [d for _, d in all_pairs]

    # ìš”ì•½/ì‚­ì œ
    if all_pairs:
        st.markdown(f"**ì„ íƒëœ í•™ê³¼ ({len(all_pairs)}ê°œ)**")

        import hashlib
        for c, d in all_pairs:
            cols = st.columns([0.85, 0.15])
            with cols[0]:
                st.write(f"{c} Â· **{d}**")
            with cols[1]:
                key = "del_" + hashlib.md5(f"{c}|{d}".encode("utf-8")).hexdigest()
                if st.button("âœ•", key=key, help="ì´ í•­ëª©ì„ ì„ íƒ í•´ì œ"):
                    st.session_state["selected_map"][c] = [
                        x for x in st.session_state["selected_map"][c] if x != d
                    ]
                    st.rerun()
    else:
        st.caption("ì•„ì§ ì„ íƒëœ í•™ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("ë‹¨ê³¼ëŒ€í•™ë³„ ì „ì²´ í•™ê³¼ ë³´ê¸°", expanded=False):
        for c in college_list:  # ì›ë˜ ìˆœì„œ ìœ ì§€
            st.markdown(f"**{c}**  \n" + " Â· ".join(by_college[c]))

    st.markdown(
    """
    <div class="sidebar-footer">
    <hr/>
    <div>Copyright. 2025 ëŒ€í•™í˜ì‹ ì§€ì›ì‚¬ì—… ì—°êµ¬ê³¼ì œ ì„œì§„ì£¼, ì „ì¬í˜„</div>
    </div>
    """,
    unsafe_allow_html=True
        )


# ========= ë³¸ë¬¸: ì§ˆì˜ â†’ RAG ì¶”ì²œ =========
st.title("KU ì „ê³µ ë§ì¶¤ ë„ì„œì¶”ì²œ")
st.caption("ì „ê³µ(í•™ê³¼) ì„ íƒ í›„, ì›í•˜ëŠ” ì£¼ì œ/í†¤/ë‚œì´ë„ë¥¼ ì…ë ¥í•˜ë©´ ì „ê³µì— ë§ì¶˜ ë„ì„œë¥¼ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.")

st.markdown("##### ")
tab_reco, tab_help = st.tabs(["âœ¨ ì¶”ì²œ", "â“ë„ì›€ë§"])

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„
st.session_state.setdefault("chat", [])

# ============ íƒ­: ì¶”ì²œ ============
with tab_reco:

    st.markdown("""
    <style>
    /* 1) ì±„íŒ… ì…ë ¥ì°½: í™”ë©´ í•˜ë‹¨ ê³ ì • + ë©”ì¸ì˜ì—­ë§Œ ì°¨ì§€ */
    div[data-testid="stChatInput"]{
    position: fixed;
    z-index: 999;
    bottom: 20px;                 /* ë°”ë‹¥ì—ì„œ ë„ìš°ê¸° */
    right: 24px;                  /* ìš°ì¸¡ ì—¬ë°± */
    left: 360px;                  /* ì‚¬ì´ë“œë°” í­(ëŒ€ëµ)ë§Œí¼ ë„ìš°ê¸°: í•„ìš”ì‹œ ì¡°ì • */
    max-width: 1100px;            /* ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ìƒí•œ */
    margin: 0 auto;               /* ì¤‘ì•™ ì •ë ¬ ëŠë‚Œ */
    background: white;
    padding: 0.75rem 1rem;
    border: 1px solid #e5e7eb;
    border-radius: 12px;
    box-shadow: 0 8px 24px rgba(0,0,0,0.08);
    }

    /* 2) ë°˜ì‘í˜•: í™”ë©´ì´ ì¢ì„ ë• ì¢Œìš° ì—¬ë°±ë§Œ ë‘ê³  ê½‰ ì°¨ê²Œ */
    @media (max-width: 1100px){
    div[data-testid="stChatInput"]{
        left: 16px;
        right: 16px;
        bottom: 12px;
    }
    }

    /* 3) ë‚´ìš©ì´ chat_input ë’¤ì— ê°€ë¦¬ì§€ ì•Šë„ë¡ ë©”ì¸ ì˜ì—­ì— í•˜ë‹¨ íŒ¨ë”© ì¶”ê°€ */
    section.main, div[data-testid="stAppViewContainer"] section{
    padding-bottom: 140px; /* chat_input ë†’ì´ + ì—¬ìœ  */
    }
                
    /* ==== Tooltip (semantic score help) - í˜ì´ì§€ ë°– ë„˜ì¹¨ ë°©ì§€ í¬í•¨ ==== */
    .tooltip {
        position: relative !important;
        display: inline-flex !important;
        align-items: center !important;
        cursor: help !important;
        border-bottom: 1px dotted #94a3b8 !important;
    }
    .tooltip::after {
        content: attr(data-tooltip) !important;
        position: absolute !important;
        right: 0 !important; left: auto !important;
        bottom: calc(100% + 10px) !important;
        transform: none !important;

        display: block !important;
        background: #111827 !important; color: #fff !important; text-align: left !important;
        font-size: 12px !important; line-height: 1.5 !important;
        padding: 8px 10px !important; border-radius: 8px !important;
        box-shadow: 0 8px 20px rgba(0,0,0,.15) !important;

        white-space: pre-line !important; overflow-wrap: anywhere !important; word-break: break-word !important;
        width: max-content !important; max-width: min(320px, calc(100vw - 32px)) !important;

        opacity: 0 !important; pointer-events: none !important; transition: opacity .15s ease !important;
        z-index: 10000 !important;
    }
    .tooltip::before {
        content: "" !important;
        position: absolute !important;
        right: 8px !important; left: auto !important;
        bottom: calc(100% + 4px) !important;
        border-width: 6px !important; border-style: solid !important; border-color: #111827 transparent transparent transparent !important;
        opacity: 0 !important; transition: opacity .15s ease !important; z-index: 10000 !important;
    }
    .tooltip:hover::after, .tooltip:hover::before { opacity: 1 !important; }
    @media (max-width: 420px){
        .tooltip::after { left:50% !important; right:auto !important; transform: translateX(-50%) !important; }
        .tooltip::before { left:50% !important; right:auto !important; transform: translateX(-50%) !important; }
    }

    </style>
    """, unsafe_allow_html=True)

    n_bm25  = st.session_state.get("n_bm25", 80)
    top_k   = st.session_state.get("top_k", 5)
    use_hyde = st.session_state.get("use_hyde", True)

    # --- ìœ í‹¸: ëŒ€í™” append ---
    def append_chat(role: str, content: str, cards: list | None = None):
        msg = {"role": role, "content": content}
        if cards:
            msg["cards"] = cards
        st.session_state["chat"].append(msg)

    # --- íˆìŠ¤í† ë¦¬ ë Œë” ---
    for turn in st.session_state["chat"]:
        with st.chat_message("user" if turn["role"] == "user" else "assistant"):
            st.markdown(turn.get("content", ""))
            cards = turn.get("cards") if isinstance(turn, dict) else None
            if cards:
                for i, it in enumerate(cards, 1):
                    render_book_card(it, i, it.get("reason", ""))

    # --- ì…ë ¥ì°½ ---
    selected_cnt = len(all_pairs)
    can_chat = (selected_cnt > 0)
    query = st.chat_input("ì „ê³µ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œë°›ì„ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", disabled=not can_chat)

    if not can_chat:
        st.info("ì „ê³µ(í•™ê³¼)ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”!")
        st.stop()

    # --- ì…ë ¥ ì²˜ë¦¬ ---
    if query:
        # 1) ìœ ì € ì§ˆë¬¸ ë¨¼ì € ê¸°ë¡ + í™”ë©´ ë…¸ì¶œ
        append_chat("user", query)
        with st.chat_message("user"):
            st.markdown(query)

        # 2) ë¡œë”© â†’ ê²€ìƒ‰/ë­í‚¹
        with st.chat_message("assistant"):
            with st.spinner("ì „ê³µì— ë§ëŠ” ì±…ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                intent = detect_intent(query)

                if intent == "ask_name":
                    # ê²°ê³¼ ì €ì¥
                    append_chat("assistant", "ì €ëŠ” KUì„¼ìŠ¤ì…ë‹ˆë‹¤. ë„ì„œì¶”ì²œì„ ë„ì™€ë“œë¦´ê²Œìš”")
                elif intent != "recommend":
                    append_chat(
                        "assistant",
                        "í˜„ì¬ëŠ” **ì „ê³µê¸°ë°˜ ì±… ì¶”ì²œ/ê²€ìƒ‰** ì§ˆë¬¸ì— ìµœì í™”ë˜ì–´ ìˆì–´ìš”.\n\n"
                        "ì˜ˆì‹œ) `AI ìœ¤ë¦¬ì˜ì‹ì— ê´€ë ¨ëœ ì±… ì¶”ì²œí•´ì¤˜`, "
                        "`ë‚´ ì „ê³µì€ ë¬´ìŠ¨ ì±…ì´ ìœ ëª…í•´?`"
                    )
                else:
                    try:
                        # ì „ê³µ ë°˜ì˜ ì¿¼ë¦¬ í™•ì¥
                        q_aug = build_query_with_major(query)

                        # BM25 í›„ë³´
                        tokenized_query = simple_tokenize(q_aug)
                        corpus = []
                        for _, r in df_books.iterrows():
                            summary = extract_summary_from_gpt(r[COL_TEXT])
                            corpus.append(simple_tokenize(f"{r[COL_TITLE]} {summary}"))
                        bm25_local = BM25Okapi(corpus)
                        scores = bm25_local.get_scores(tokenized_query)
                        order = np.argsort(-np.asarray(scores))[:int(n_bm25)]
                        cand = df_books.iloc[order].reset_index(drop=True)

                        # ì„ë² ë”© ì¬ë­í‚¹(+ì˜µì…˜ HyDE)
                        ranked = rerank(q_aug, cand, top_k=int(top_k), use_hyde=use_hyde)

                        # ì¶”ì²œ ì´ìœ  ìƒì„±
                        reasons = make_reasons(q_aug, ranked)

                        # ì¹´ë“œ ë°ì´í„° ìƒì„±
                        cards = []
                        for i, r in enumerate(ranked):
                            cards.append({
                                "title": r["title"],
                                "author": r["author"],
                                "publisher": r["publisher"],
                                "genre": extract_genre_from_gpt(r.get("text","")),
                                "reason": reasons[i] if i < len(reasons) else "",
                                "score": r.get("score", 0.0)
                            })

                        if cards:
                            ack = short_acknowledge(query)
                            st.markdown(ack)

                            # append_chat("assistant", "### âœ… ì¶”ì²œ ê²°ê³¼", cards=cards)
                            append_chat("assistant", ack, cards=cards)
                        else:
                            append_chat("assistant", "ì¡°ê±´ì— ë§ëŠ” ì±…ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì „ê³µ/ì£¼ì œë¥¼ ì¡°ê¸ˆ ë„“í˜€ë³¼ê¹Œìš”?")
                    except Exception as e:
                        append_chat("assistant", f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

        # 3) rerun â†’ ìœ„ì—ì„œ íˆìŠ¤í† ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹¤ì‹œ ë Œë”
        st.rerun()

    # --- ë¹ˆ ìƒíƒœ ë°•ìŠ¤ ---
    if not st.session_state["chat"]:
        st.markdown(
            """
            <div class="emptystate" style="border:1px dashed rgba(0,0,0,.15);border-radius:16px;padding:16px;background:#fff;">
              <h4 style="margin:0 0 8px;color:#A6192E;">ì•„ì§ ì¶”ì²œì„ ì‹œì‘í•˜ì§€ ì•Šì•˜ì–´ìš”</h4>
              <div>ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ë¬¼ì–´ë³´ì„¸ìš”:</div>
              <ul style="margin-top:6px;">
                <li>ì¡°ì§ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì´ˆë³´ììš© ì±… ì¶”ì²œí•´ì¤˜</li>
                <li>ë‚´ ì „ê³µì€ ë¬´ìŠ¨ ì±…ì´ ì í•©í•´?</li>
              </ul>
            </div>
            """,
            unsafe_allow_html=True
        )
